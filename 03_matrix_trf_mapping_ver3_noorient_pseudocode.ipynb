{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description: \n",
    "\n",
    "this is the pseudo code of mapping the CONTCAR of DFT calculation to reference structure, which is consists 3 types of of Li: 48h type 1, 48h type 2, and 24g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import shutil\n",
    "from itertools import islice\n",
    "from itertools import repeat\n",
    "from addict import Dict\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# pymatgen libraries\n",
    "from pymatgen.core.structure import Structure\n",
    "from pymatgen.transformations.standard_transformations import SupercellTransformation\n",
    "from pymatgen.analysis.structure_matcher import StructureMatcher\n",
    "from pymatgen.io.cif import CifWriter\n",
    "from pymatgen.io.vasp.inputs import Poscar\n",
    "\n",
    "from get_weirdos_ver3_new import splitall, copy_rename_single_file, copy_rename_files_savedir, check_folder_existance, get_structure_with_library, get_structure_with_linalg, get_structure_with_linalg_combinded_with_library, get_coor_structure24_dict_iterated, get_structure_with_linalg_orientated, get_orientated_positive_lessthan1_cif, get_orientated_positive_lessthan1_poscar, diagonalizing_latticeconstantsmatrix, get_coor_dict_structure, get_positive_lessthan1_poscarcontcar, mic_eucledian_distance_cartesian, get_flag_map_weirdos_el, rewrite_cif_w_correct_Li_idx, rewrite_cif_w_correct_Li_idx_weirdos_appended, format_spacing_cif, create_cif_pymatgen, ascending_Li, get_latticeconstant_structure_dict_iterated, get_fractional_to_cartesian_matrix, get_fractional_to_cartesian_coor\n",
    "from get_weirdos_ver3_new import get_idx_coor_limapped_weirdos_dict, plot_energy_vs_latticeconstant\n",
    "from get_weirdos_ver3_new import get_dx_dz_init\n",
    "from get_weirdos_ver3_new import varying_radius_vs_sumweirdosLi, plot_varying_radius_vs_sumweirdosLi\n",
    "from get_weirdos_ver3_new import get_flag_map_weirdos_48htype2_el, get_flag_map_weirdos_48htypesmerged_el, get_distance_weirdos_litype2_el, get_idx_weirdos_litype2_el, idx_correcting_mapped_litype2_el, create_combine_structure, get_distance_weirdos_litype2_label_el\n",
    "\n",
    "direc = os.getcwd() # get current working directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_perfect_poscar_48n24 = \"Li6PS5Cl_type2.cif\"\n",
    "max_mapping_radius = 0.043 \n",
    "max_mapping_radius_48htype2 = 0.074\n",
    "file_perfect_poscar_24 = \"Li6PS5Cl_24_mod_2p27291.cif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_perfect_poscar_24 = os.path.join(directory, file_perfect_poscar_24)\n",
    "path_perfect_poscar_48n24 = os.path.join(directory, file_perfect_poscar_48n24)\n",
    "\n",
    "ref_structure_48n24 = Structure.from_file(path_perfect_poscar_48n24)\n",
    "\n",
    "file_loc_important_cols = pd.DataFrame() # dataframe contain all important information"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orientation (if needed. not important now)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONTCAR of path 0 (perfect system) wrt structure_reference (24g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orientation():\n",
    "        # get the structure of reference file 24g\n",
    "        structure_reference = Structure.from_file(path_perfect_poscar_24)\n",
    "        \n",
    "        # get the scaling, translation, mapping of CONTCAR of path 0 (perfect system) wrt structure_reference (24g)\n",
    "            # 3 different methods to compare. results are same\n",
    "        get_structure_with_library()\n",
    "        get_structure_with_linalg()\n",
    "        get_structure_with_linalg_combinded_with_library()\n",
    "\n",
    "        # then copy scaling, translation, mapping of path 0 to other paths of each corresponding geometry folder\n",
    "        file_loc_important_cols[\"scaling\"][idx] = file_loc_important_cols[\"scaling\"][idx_path_0].copy()\n",
    "        file_loc_important_cols[\"translation\"][idx] = file_loc_important_cols[\"translation\"][idx_path_0].copy()\n",
    "        file_loc_important_cols[\"mapping\"][idx] = file_loc_important_cols[\"mapping\"][idx_path_0].copy()\n",
    "\n",
    "    return file_loc_important_cols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other folders (NON perfect system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_structure_with_linalg(file_loc_important_cols) # to all structure "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get coordinates of the structures as library: Li, P, S, Cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference structure\n",
    "coor_structure_init_dict = get_coor_dict_structure(ref_structure_48n24)\n",
    "# all structures geometry and path\n",
    "get_coor_structure24_dict_iterated(file_loc_important_cols)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## turn coordinate x, y, z in CONTCAR into 0 < coor < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_lessthan1_poscarcontcar():\n",
    "    df_positive_val = df[['coord_x', 'coord_y', 'coord_z']]\n",
    "    for idx_a, coord_x in enumerate(df_positive_val['coord_x']):\n",
    "        while float(coord_x) < 0.0:\n",
    "            coord_x = float(coord_x) + 1.0\n",
    "        while float(coord_x) > 1:\n",
    "            coord_x = float(coord_x) - 1\n",
    "        df_positive_val['coord_x'][idx_a] = '{:.{width}f}'.format(float(coord_x), width=n_decimal)\n",
    "\n",
    "    for idx_a, coord_y in enumerate(df_positive_val['coord_y']):\n",
    "        while float(coord_y) < 0.0:\n",
    "            coord_y = float(coord_y) + 1.0\n",
    "        while float(coord_y) > 1:\n",
    "            coord_y = float(coord_y) - 1\n",
    "        df_positive_val['coord_y'][idx_a] = '{:.{width}f}'.format(float(coord_y), width=n_decimal)\n",
    "\n",
    "    for idx_a, coord_z in enumerate(df_positive_val['coord_z']):\n",
    "        while float(coord_z) < 0.0:\n",
    "            coord_z = float(coord_z) + 1.0\n",
    "        while float(coord_z) > 1:\n",
    "            coord_z = float(coord_z) - 1\n",
    "        df_positive_val['coord_z'][idx_a] = '{:.{width}f}'.format(float(coord_z), width=n_decimal)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map with respect to all Li types (48h type 1, 48h type 2, and 24g) with the small max_mapping_radius (i.e. 0.043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flag_map_weirdos_el(dataframe, coor_structure_init_dict, el, max_mapping_radius):\n",
    "    # el = \"Li\". as we want to map Li only\n",
    "    coor_origin120_el_init = coor_structure_init_dict[el]\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        atom_mapping_el = {} \n",
    "        atom_mapping_el_w_dist = {} \n",
    "        coor_weirdos_el = []\n",
    "        coor_weirdos_el_dict = {}\n",
    "\n",
    "        # all CONTCAR with 0 < coor value < 1. take the Li only\n",
    "        coor_origin24_el_init = dataframe.at[idx, \"subdir_positive_CONTCAR\"][el]\n",
    "        \n",
    "        coor_reduced120_el = coor_origin120_el_init.copy()\n",
    "        coor_weirdos_el = coor_origin24_el_init.copy()    \n",
    "\n",
    "        # outer loop: reference structure with 120 li-ions\n",
    "        for idx120, coor120 in enumerate(coor_origin120_el_init):        \n",
    "            counter = 0\n",
    "            atom_mapping_w_dist_dict = {}\n",
    "            distance_prev = float(\"inf\")\n",
    "            closest24 = None\n",
    "            \n",
    "            # inner loop: CONTCAR with 24 Li\n",
    "            for idx24, coor24 in enumerate(coor_origin24_el_init):\n",
    "                distance = mic_eucledian_distance(coor120, coor24)\n",
    "                \n",
    "                if distance < max_mapping_radius:\n",
    "                    # get the coor with the closest distance\n",
    "                    if distance < distance_prev:\n",
    "                        distance_prev = distance\n",
    "                        closest24 = coor24\n",
    "                        counter = counter + 1\n",
    "\n",
    "                # flag if any coor120 fits in more than one coor24 \n",
    "                if counter > 1:\n",
    "                    dataframe.at[idx, col_flag_el] = \"True\"\n",
    "                \n",
    "            if closest24 is not None:\n",
    "                atom_mapping_w_dist_dict['closest24'] = tuple(closest24)\n",
    "                atom_mapping_w_dist_dict['dist'] = distance_prev\n",
    "\n",
    "                # create dictionary for coor120, its closest coor24, and distance\n",
    "                if tuple(coor120) in atom_mapping_el_w_dist:\n",
    "                    atom_mapping_el_w_dist[tuple(coor120)].append(atom_mapping_w_dist_dict)\n",
    "                else:\n",
    "                    atom_mapping_el_w_dist[tuple(coor120)] = atom_mapping_w_dist_dict\n",
    "                    \n",
    "                if tuple(coor120) in atom_mapping_el:\n",
    "                    atom_mapping_el[tuple(coor120)].append(closest24)\n",
    "                else:\n",
    "                    atom_mapping_el[tuple(coor120)] = tuple(closest24)\n",
    "\n",
    "                coor_weirdos_el = [arr for arr in coor_weirdos_el if not np.array_equal(arr, closest24)]\n",
    "\n",
    "            # if no coor24 fits within the radius. delete the coor120. this is for the mapped CONTCAR\n",
    "            if counter == 0:\n",
    "                coor_reduced120_el = [arr for arr in coor_reduced120_el if not np.array_equal(arr, coor120)]\n",
    "\n",
    "        # get any coor24 that has more than one coor120 fits within the radius\n",
    "        duplicate_closest24_w_data = get_duplicate_closest24_w_data(atom_mapping_el_w_dist)\n",
    "\n",
    "        # get the new reduced coor120, based on the closest distance if it has multiple close coor120 within the radius\n",
    "        if len(duplicate_closest24_w_data) > 0:\n",
    "            atom_mapping_el_w_dist_filtered = get_atom_mapping_el_w_dist_filtered(atom_mapping_el_w_dist)\n",
    "            coor_reduced120_el_new = [list(key) for key in atom_mapping_el_w_dist_filtered.keys()]\n",
    "        else:\n",
    "            coor_reduced120_el_new = coor_reduced120_el\n",
    "\n",
    "        sum_weirdos_el = len(coor_weirdos_el)\n",
    "        sum_mapped_el = len(coor_reduced120_el)\n",
    "        sum_mapped_el_new = len(coor_reduced120_el_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum image convection eucledian distance\n",
    "def mic_eucledian_distance(coor1, coor2):\n",
    "    x_coor1, y_coor1, z_coor1 = coor1\n",
    "    x_coor2, y_coor2, z_coor2 = coor2\n",
    "    \n",
    "    delta_x = x_coor1 - x_coor2\n",
    "    delta_y = y_coor1 - y_coor2\n",
    "    delta_z = z_coor1 - z_coor2\n",
    "\n",
    "    distance = math.sqrt(sum([(apply_pbc(delta_x))**2, (apply_pbc(delta_y))**2, (apply_pbc(delta_z))**2]))\n",
    "    return distance\n",
    "\n",
    "# periodic boundary condition\n",
    "def apply_pbc(value):\n",
    "    if abs(value) > 0.5:\n",
    "        return 1 - abs(value)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duplicate_closest24_w_data(dict):\n",
    "    duplicate_closest24 = {}\n",
    "    for coor120, value in dict.items():\n",
    "        closest24 = value[\"closest24\"]\n",
    "        dist = value[\"dist\"]\n",
    "        if closest24 in duplicate_closest24:\n",
    "            duplicate_closest24[closest24].append({\"coor120\": coor120, \"dist\": dist})\n",
    "        else:\n",
    "            duplicate_closest24[closest24] = [{\"coor120\": coor120, \"dist\": dist}]\n",
    "\n",
    "    duplicate_closest24_w_data = {}\n",
    "    for closest24, coor120s_dists in duplicate_closest24.items():\n",
    "        if len(coor120s_dists) > 1:\n",
    "            duplicate_closest24_w_data[f\"Duplicate closest24: {closest24}\"] = [{\"coor120s and dists\": coor120s_dists}]\n",
    "\n",
    "    return duplicate_closest24_w_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_atom_mapping_el_w_dist_filtered(dict):\n",
    "    filtered_data = {}\n",
    "    for coor120, value in dict.items():\n",
    "        closest24 = value[\"closest24\"]\n",
    "        dist = value[\"dist\"]\n",
    "        if closest24 in filtered_data:\n",
    "            if dist < filtered_data[closest24][\"dist\"]:\n",
    "                filtered_data[closest24] = {\"coor120\": coor120, \"dist\": dist}\n",
    "        else:\n",
    "            filtered_data[closest24] = {\"coor120\": coor120, \"dist\": dist}\n",
    "\n",
    "    atom_mapping_el_w_dist_filtered = {entry[\"coor120\"]: {\"closest24\": key, \"dist\": entry[\"dist\"]} for key, entry in filtered_data.items()}\n",
    "    return atom_mapping_el_w_dist_filtered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping with larger radius and specifically only for Li 48h type 2\n",
    "max_mapping_radius_48htype2 (i.e. 0.76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basically same code like above. but different in input. \n",
    "# we use coor_weirdos_Li_dict as input instead of coordinate of CONTCAR structure\n",
    "# for this I didn't rename the variable\n",
    "\n",
    "def get_flag_map_weirdos_48htype2_el(dataframe, coor_structure_init_dict, el, max_mapping_radius_48htype2):\n",
    "    coor_origin120_el_init = coor_structure_init_dict[el]                       \n",
    "\n",
    "    coor_li48htype1_ref = coor_origin120_el_init[0:48]\n",
    "    coor_li48htype2_ref = coor_origin120_el_init[48:96] \n",
    "    coor_li24g_ref = coor_origin120_el_init[96:120]\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        atom_mapping_el = {} \n",
    "        atom_mapping_el_w_dist = {} \n",
    "        coor_weirdos_el = []\n",
    "\n",
    "        coor_origin24_el_init = dataframe.at[idx, f\"coor_weirdos_{el}_dict\"][el]    # here is the difference !!!\n",
    "        \n",
    "        # ONLY process the one that has weirdos\n",
    "        if len(coor_origin24_el_init) > 0:\n",
    "            coor_reduced120_el = coor_li48htype2_ref.copy()\n",
    "            coor_weirdos_el = coor_origin24_el_init.copy()    \n",
    "\n",
    "            # outer loop: coordinate of Li 48h type 2\n",
    "            for idx120, coor120 in enumerate(coor_li48htype2_ref):        \n",
    "                counter = 0\n",
    "                atom_mapping_w_dist_dict = {}\n",
    "                distance_prev = float(\"inf\")\n",
    "                closest24 = None\n",
    "\n",
    "                # inner loop: coordinate of weirdos\n",
    "                for idx24, coor24 in enumerate(coor_origin24_el_init):\n",
    "                    distance = mic_eucledian_distance(coor120, coor24)\n",
    "                    \n",
    "                    if distance < max_mapping_radius_48htype2:\n",
    "                        if distance < distance_prev:\n",
    "                            distance_prev = distance\n",
    "                            closest24 = coor24\n",
    "                            counter = counter + 1\n",
    "                \n",
    "                    if counter > 1:\n",
    "                        dataframe.at[idx, col_flag_48htype2_el] = \"True\"\n",
    "\n",
    "                # the rest are the same like before\n",
    "                if closest24 is not None:\n",
    "                    atom_mapping_w_dist_dict['closest24'] = tuple(closest24)\n",
    "                    atom_mapping_w_dist_dict['dist'] = distance_prev\n",
    "\n",
    "                    if tuple(coor120) in atom_mapping_el_w_dist:\n",
    "                        atom_mapping_el_w_dist[tuple(coor120)].append(atom_mapping_w_dist_dict)\n",
    "                    else:\n",
    "                        atom_mapping_el_w_dist[tuple(coor120)] = atom_mapping_w_dist_dict\n",
    "                        \n",
    "                    if tuple(coor120) in atom_mapping_el:\n",
    "                        atom_mapping_el[tuple(coor120)].append(closest24)\n",
    "                    else:\n",
    "                        atom_mapping_el[tuple(coor120)] = tuple(closest24)\n",
    "\n",
    "                    coor_weirdos_el = [arr for arr in coor_weirdos_el if not np.array_equal(arr, closest24)]\n",
    "\n",
    "                if counter == 0:\n",
    "                    coor_reduced120_el = [arr for arr in coor_reduced120_el if not np.array_equal(arr, coor120)]\n",
    "\n",
    "            duplicate_closest24_w_data = get_duplicate_closest24_w_data(atom_mapping_el_w_dist)\n",
    "\n",
    "            if len(duplicate_closest24_w_data) > 0:\n",
    "                atom_mapping_el_w_dist_filtered = get_atom_mapping_el_w_dist_filtered(atom_mapping_el_w_dist)\n",
    "                coor_reduced120_el_new = [list(key) for key in atom_mapping_el_w_dist_filtered.keys()]\n",
    "            else:\n",
    "                coor_reduced120_el_new = coor_reduced120_el\n",
    "\n",
    "            sum_weirdos_el = len(coor_weirdos_el)\n",
    "            sum_mapped_el = len(coor_reduced120_el)\n",
    "            sum_mapped_el_new = len(coor_reduced120_el_new)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the results of both mapping with different radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flag_map_weirdos_48htypesmerged_el(dataframe, el):\n",
    "    # columns from the 1st mapping to be called later\n",
    "    col_atom_mapping_el = f\"atom_mapping_{el}\"\n",
    "    col_atom_mapping_el_w_dist = f\"atom_mapping_{el}_w_dist\"\n",
    "    col_duplicate_closest24_w_data_el = f\"duplicate_closest24_w_data_{el}\"\n",
    "    col_coor_reduced120_el_new = f\"coor_reduced120_{el}_new\"\n",
    "    col_sum_mapped_el_new = f\"sum_mapped_{el}_new\"\n",
    "    col_sum_sanitycheck_el_new = f\"sum_sanitycheck_{el}_new\"\n",
    "\n",
    "    # columns from the 2nd mapping to be called later\n",
    "    col_atom_mapping_48htype2_el = f\"atom_mapping_48htype2_{el}\"\n",
    "    col_atom_mapping_48htype2_el_w_dist = f\"atom_mapping_48htype2_{el}_w_dist\"\n",
    "    col_coor_weirdos_48htype2_el = f\"coor_weirdos_48htype2_{el}\"\n",
    "    col_sum_weirdos_48htype2_el = f\"sum_weirdos_48htype2_{el}\"\n",
    "    col_duplicate_closest24_w_data_48htype2_el = f\"duplicate_closest24_w_data_48htype2_{el}\"\n",
    "    col_coor_reduced120_48htype2_el_new = f\"coor_reduced120_48htype2_{el}_new\"\n",
    "    col_sum_mapped_48htype2_el_new = f\"sum_mapped_48htype2_{el}_new\"\n",
    "    col_sum_sanitycheck_48htype2_el_new = f\"sum_sanitycheck_48htype2_{el}_new\"\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        # 1st atom mapping results. to be merged.\n",
    "        atom_mapping_el = dataframe.at[idx, col_atom_mapping_el]\n",
    "        atom_mapping_el_w_dist = dataframe.at[idx, col_atom_mapping_el_w_dist]\n",
    "        coor_reduced120_el_new = dataframe.at[idx, col_coor_reduced120_el_new]\n",
    "        # 2nd atom mapping results. to be merged.\n",
    "        atom_mapping_48htype2_el = dataframe.at[idx, col_atom_mapping_48htype2_el]\n",
    "        atom_mapping_48htype2_el_w_dist = dataframe.at[idx, col_atom_mapping_48htype2_el_w_dist]\n",
    "        coor_reduced120_48htype2_el_new = dataframe.at[idx, col_coor_reduced120_48htype2_el_new]\n",
    "\n",
    "        # these are the absolute result. no need further merging.\n",
    "        coor_weirdos_48htypesmerged_el = dataframe.at[idx, col_coor_weirdos_48htype2_el]\n",
    "        sum_weirdos_48htypesmerged_el = dataframe.at[idx, col_sum_weirdos_48htype2_el]\n",
    "        duplicate_closest24_w_data_48htypesmerged = dataframe.at[idx, col_duplicate_closest24_w_data_48htype2_el]\n",
    "        \n",
    "        # initializing list for merging\n",
    "        coor_reduced120_48htypesmerged_el_new = []\n",
    "\n",
    "        # merge the mapping dictionary from both mapping results\n",
    "        # mapping dictionary has coor120 as key, coor24 as value\n",
    "        atom_mapping_48htypesmerged_el = merge_dictionaries(atom_mapping_el, atom_mapping_48htype2_el)\n",
    "        # check if after the merging there are double coor24\n",
    "        duplicate_coor24s = check_duplicatevalues(atom_mapping_48htypesmerged_el)\n",
    "        if len(duplicate_coor24s) > 1:        \n",
    "            dataframe.at[idx, f\"flag_48htypesmerged_{el}\"] = \"True\"\n",
    "        \n",
    "        # merging mapping results with distance\n",
    "        atom_mapping_48htypesmerged_el_w_dist = merge_dictionaries(atom_mapping_el_w_dist, atom_mapping_48htype2_el_w_dist)\n",
    "\n",
    "        # merge the mapped coordinate from both mapping results\n",
    "        if coor_reduced120_48htype2_el_new.ndim == coor_reduced120_el_new.ndim:\n",
    "            coor_reduced120_48htypesmerged_el_new = np.concatenate((coor_reduced120_el_new, coor_reduced120_48htype2_el_new), axis=0)\n",
    "        # if 2nd mapping results in no coordinate, then copy the result of the 1st mapping\n",
    "        elif coor_reduced120_48htype2_el_new.ndim == 1:\n",
    "            coor_reduced120_48htypesmerged_el_new = np.array(coor_reduced120_el_new.copy())\n",
    "        # accordingly for 1st mapping results\n",
    "        elif coor_reduced120_el_new.ndim == 1:\n",
    "            coor_reduced120_48htypesmerged_el_new = np.array(coor_reduced120_48htype2_el_new.copy())\n",
    "        else:\n",
    "            print(f\"coor_reduced120_48htype2_el_new or coor_reduced120_el_new has no correct dimension at idx: {idx}\")\n",
    "\n",
    "        sum_mapped_48htypesmerged_el_new = len(coor_reduced120_48htypesmerged_el_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two dictionaries\n",
    "def merge_dictionaries(dict1, dict2):\n",
    "    merged_dict = defaultdict(list)\n",
    "\n",
    "    for d in (dict1, dict2): \n",
    "        for key, value in d.items():\n",
    "            merged_dict[key].append(value)\n",
    "    \n",
    "    return merged_dict\n",
    "\n",
    "# check duplicate values\n",
    "def check_duplicate_values(dictionary):\n",
    "    seen_values = set()\n",
    "    duplicate_values = set()\n",
    "\n",
    "    for value in dictionary.values():\n",
    "        value_tuple = tuple(value) \n",
    "        if value_tuple in seen_values:\n",
    "            duplicate_values.add(value_tuple)\n",
    "        else:\n",
    "            seen_values.add(value_tuple)\n",
    "\n",
    "    return duplicate_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get distance of weirdos, its top 3 closest coor120, and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_weirdos_litype2_label_el(dataframe, coor_structure_init_dict, el, litype2):\n",
    "    # to do: add idx of weirdo and coor120\n",
    "    coor_origin120_el_init = coor_structure_init_dict[el]\n",
    "\n",
    "    coor_li48htype1_ref = coor_origin120_el_init[0:48]\n",
    "    coor_li48htype2_ref = coor_origin120_el_init[48:96]\n",
    "    coor_li24g_ref = coor_origin120_el_init[96:120]\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        dist_weirdos_atom120_el = []\n",
    "        dist_weirdos_el = []\n",
    "        coorweirdo_dist_label_coor120_idxweirdo_idx120_el = {}\n",
    "\n",
    "        # coordinate of weirdos\n",
    "        coor_weirdos_el = dataframe.at[idx, f\"coor_weirdos_48htype2_{el}\"]\n",
    "\n",
    "        # process only if weirdo exists\n",
    "        if len(coor_weirdos_el) > 0:\n",
    "\n",
    "            # outer loop: coor weirdo\n",
    "            for coor_weirdo in coor_weirdos_el:\n",
    "                distance_weirdo_prev = float('inf')\n",
    "\n",
    "                coorweirdo_dist_label_coor120_idxweirdo_idx120_el[tuple(coor_weirdo)] = []\n",
    "                \n",
    "                # inner loop: reference structure with 120 li-ions\n",
    "                for idx120, coor120 in enumerate(coor_origin120_el_init):\n",
    "                    coorweirdo_dist_label_coor120_val_el = {}\n",
    "            \n",
    "                    distance_weirdo = mic_eucledian_distance(coor120, coor_weirdo)\n",
    "\n",
    "                    coorweirdo_dist_label_coor120_val_el['dist'] = distance_weirdo\n",
    "\n",
    "                    # get label of 48htype1 and create dictionary = key: coor_weirdo; values: distance, type, coor120\n",
    "                    for idx_li48htype1_temp, coor_li48htype1_ref_temp in enumerate(coor_li48htype1_ref):\n",
    "                        if (coor120 == coor_li48htype1_ref_temp).all():\n",
    "                            coorweirdo_dist_label_coor120_val_el[\"type\"] = \"48htype1\"\n",
    "                            coorweirdo_dist_label_coor120_val_el[\"coor120\"] = tuple(coor120)\n",
    "                            if tuple(coor_weirdo) in coorweirdo_dist_label_coor120_idxweirdo_idx120_el:\n",
    "                                coorweirdo_dist_label_coor120_idxweirdo_idx120_el[tuple(coor_weirdo)].append(coorweirdo_dist_label_coor120_val_el)\n",
    "                            else:\n",
    "                                coorweirdo_dist_label_coor120_idxweirdo_idx120_el[tuple(coor_weirdo)] = coorweirdo_dist_label_coor120_val_el\n",
    "                    # get label of 48htype2\n",
    "                    for idx_li48htype2_temp, coor_li48htype2_ref_temp in enumerate(coor_li48htype2_ref):\n",
    "                        if (coor120 == coor_li48htype2_ref_temp).all():\n",
    "                            coorweirdo_dist_label_coor120_val_el[\"type\"] = \"48htype2\"\n",
    "                            coorweirdo_dist_label_coor120_val_el[\"coor120\"] = tuple(coor120)\n",
    "                            if tuple(coor_weirdo) in coorweirdo_dist_label_coor120_idxweirdo_idx120_el:\n",
    "                                coorweirdo_dist_label_coor120_idxweirdo_idx120_el[tuple(coor_weirdo)].append(coorweirdo_dist_label_coor120_val_el)\n",
    "                            else:\n",
    "                                coorweirdo_dist_label_coor120_idxweirdo_idx120_el[tuple(coor_weirdo)] = coorweirdo_dist_label_coor120_val_el\n",
    "                    # get label of 24g\n",
    "                    for idx_24g_temp, coor_li24g_ref_temp in enumerate(coor_li24g_ref):\n",
    "                        if (coor120 == coor_li24g_ref_temp).all():\n",
    "                            coorweirdo_dist_label_coor120_val_el[\"type\"] = \"24g\"\n",
    "                            coorweirdo_dist_label_coor120_val_el[\"coor120\"] = tuple(coor120)\n",
    "                            if tuple(coor_weirdo) in coorweirdo_dist_label_coor120_idxweirdo_idx120_el:\n",
    "                                coorweirdo_dist_label_coor120_idxweirdo_idx120_el[tuple(coor_weirdo)].append(coorweirdo_dist_label_coor120_val_el)\n",
    "                            else:\n",
    "                                coorweirdo_dist_label_coor120_idxweirdo_idx120_el[tuple(coor_weirdo)] = coorweirdo_dist_label_coor120_val_el\n",
    "\n",
    "                # sort dictionary based on asceding distance value\n",
    "                sorted_coorweirdo_dist_label_coor120_idxweirdo_idx120_el = {\n",
    "                                                                    k: sorted(v, key=lambda x: x['dist'])\n",
    "                                                                    for k, v in coorweirdo_dist_label_coor120_idxweirdo_idx120_el.items()\n",
    "                                                                }\n",
    "                \n",
    "                # take top3 distance and its values\n",
    "                top3_sorted_coorweirdo_dist_label_coor120_idxweirdo_idx120_el = {k: v[0:3] for k, v in sorted_coorweirdo_dist_label_coor120_idxweirdo_idx120_el.items()}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get index of weirdos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_weirdos_litype2_el(dataframe, el, litype2):\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        coor_origin24_el_init = dataframe.at[idx, \"subdir_positive_CONTCAR\"][el]\n",
    "        \n",
    "        idx_weirdos_el = []\n",
    "\n",
    "        # outer loop: CONTCAR \n",
    "        for i, given_arr in enumerate(coor_origin24_el_init):\n",
    "            \n",
    "            coor_weirdos_el = dataframe.at[idx, f\"coor_weirdos_48htype2_{el}\"]\n",
    "\n",
    "            # process only if weirdo exists\n",
    "            if len(coor_weirdos_el) > 0:\n",
    "\n",
    "                # inner loop: coor of weirdo \n",
    "                for arr in coor_weirdos_el:\n",
    "                    # get the index based on CONTCAR\n",
    "                    if (arr == given_arr).all():\n",
    "                        idx_weirdos_el.append(i)\n",
    "\n",
    "        idx0_weirdos_el = idx_weirdos_el\n",
    "        sum_weirdos_el = len(idx_weirdos_el)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting the index of the mapped li-ion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_correcting_mapped_litype2_el(dataframe, el, litype2):\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        coor_origin24_el_init = dataframe.at[idx, \"subdir_positive_CONTCAR\"][el] \n",
    "        coor_reduced120_el_new = dataframe.at[idx, f\"coor_reduced120_48htypesmerged_{el}_new\"]\n",
    "\n",
    "        idx_correcting_el = []\n",
    "        atom_mapping_el_w_dist_idx24 = {} \n",
    "        idx_coor_el = {}\n",
    "\n",
    "        # outer loop: merged coor of 1st and 2nd mapping\n",
    "        for idx120, coor120 in enumerate(coor_reduced120_el_new):\n",
    "            distance_prev = float(\"inf\")\n",
    "            closest24 = None\n",
    "            idx_closest24 = None\n",
    "            atom_mapping_w_dist_idx24_dict = {}\n",
    "\n",
    "            atom_mapping_el_w_dist_idx24[tuple(coor120)] = []\n",
    "\n",
    "            # inner loop: CONTCAR\n",
    "            for idx24, coor24 in enumerate(coor_origin24_el_init):\n",
    "                distance = mic_eucledian_distance(coor120, coor24)\n",
    "\n",
    "                if distance != 0:\n",
    "                    if distance < distance_prev:\n",
    "                        distance_prev = distance\n",
    "                        closest24 = coor24\n",
    "                        idx_closest24 = idx24\n",
    "            \n",
    "            idx_correcting_el.append(idx_closest24)\n",
    "\n",
    "            # create dictionary: coor120, closest24, dist, idx_closest24\n",
    "            if closest24 is not None:\n",
    "                atom_mapping_w_dist_idx24_dict['closest24'] = tuple(closest24)\n",
    "                atom_mapping_w_dist_idx24_dict['dist'] = distance\n",
    "                atom_mapping_w_dist_idx24_dict['idx_closest24'] = idx_closest24\n",
    "\n",
    "                if tuple(coor120) in atom_mapping_el_w_dist_idx24:\n",
    "                    atom_mapping_el_w_dist_idx24[tuple(coor120)].append(atom_mapping_w_dist_idx24_dict)\n",
    "                else:\n",
    "                    atom_mapping_el_w_dist_idx24[tuple(coor120)] = atom_mapping_w_dist_idx24_dict\n",
    "        \n",
    "        # correcting the index\n",
    "        for i in range(len(idx_correcting_el)):\n",
    "            idx_coor_el[idx_correcting_el[i]] = coor_reduced120_el_new[i]\n",
    "        sorted_idx_coor_el = {key: val for key, val in sorted(idx_coor_el.items())}\n",
    "        sorted_coor = list(sorted_idx_coor_el.values())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing as CIF file (not yet summarized as pseudocode)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create combine structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combine_structure(dataframe, destination_directory, amount_Li, amount_P, amount_S, var_savefilename):\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        coor_combined = []\n",
    "\n",
    "        new_structure = Structure.from_file(dataframe['subdir_CONTCAR'][idx])\n",
    "        coor_origin24_init = dataframe.at[idx, \"subdir_positive_CONTCAR\"]\n",
    "        coor_reduced120_Li = dataframe.at[idx, \"coor_reduced120_corrected_Li_new\"]\n",
    "\n",
    "        coor_structure_init_P = coor_origin24_init[\"P\"]\n",
    "        coor_structure_init_S = coor_origin24_init[\"S\"]\n",
    "        coor_structure_init_Cl = coor_origin24_init[\"Cl\"]\n",
    "\n",
    "        coor_mapped_Li = np.array(coor_reduced120_Li)\n",
    "        coor_origin_P = np.array(coor_structure_init_P)\n",
    "        coor_origin_S = np.array(coor_structure_init_S)\n",
    "        coor_origin_Cl = np.array(coor_structure_init_Cl)\n",
    "    \n",
    "        ## get the combined coordinate of the mapped Li with all other original elements\n",
    "        for m in coor_mapped_Li:\n",
    "            coor_combined.append(np.array(m))\n",
    "        for n in coor_origin_P:\n",
    "            coor_combined.append(np.array(n))\n",
    "        for o in coor_origin_S:\n",
    "            coor_combined.append(np.array(o))\n",
    "        for p in coor_origin_Cl:\n",
    "            coor_combined.append(np.array(p))\n",
    "        \n",
    "        coor_combined_array = [arr.tolist() for arr in coor_combined]\n",
    "\n",
    "        ## getting the index\n",
    "        amount_Li_temp = len(coor_reduced120_Li)\n",
    "        amount_P_temp = len(coor_structure_init_P)\n",
    "        amount_S_temp = len(coor_structure_init_S)\n",
    "        amount_Cl_temp = len(coor_structure_init_Cl)\n",
    "\n",
    "        # TO DO: write manually to change the line with Li{i}, where i = #of index based on the orientated positive\n",
    "        idx_mapped_Li = np.arange(amount_Li_temp)\n",
    "        idx_origin_P = np.arange(amount_P_temp) + amount_Li\n",
    "        idx_origin_S = np.arange(amount_S_temp) + amount_Li + amount_P\n",
    "        idx_origin_Cl = np.arange(amount_Cl_temp) + amount_Li + amount_P + amount_S\n",
    "\n",
    "        idx_species_combined_idx0 = np.concatenate((idx_mapped_Li, idx_origin_P, idx_origin_S, idx_origin_Cl))\n",
    "        idx_species_combined_idx0_int = idx_species_combined_idx0.astype(int).tolist()\n",
    "\n",
    "        ## creating the structure file of combined elements\n",
    "        selected_species_combined = [new_structure.species[i] for i in idx_species_combined_idx0_int]\n",
    "        structure_combined = Structure(new_structure.lattice, selected_species_combined, coor_combined_array)\n",
    "        cif_combined = CifWriter(structure_combined)\n",
    "        source_filename = f\"{int(dataframe['geometry'][idx])}_{int(dataframe['path'][idx])}_{var_savefilename}.cif\"\n",
    "        source_filename_path = os.path.join(destination_directory, source_filename)\n",
    "        cif_combined.write_file(source_filename_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rewrite CIF file with correct Li index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_cif_w_correct_Li_idx(dataframe, destination_directory, amount_Li, amount_P, amount_S, amount_Cl, var_savefilename_init, var_savefilename_new):\n",
    "    col_idx_without_weirdos = \"idx_without_weirdos\"\n",
    "\n",
    "    dataframe[col_idx_without_weirdos] = [np.array([]) for _ in range(len(dataframe.index))]\n",
    "    \n",
    "    search_string = \"Li  Li0\"\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        idx0_weirdos_Li = dataframe[\"idx0_weirdos_Li\"][idx]\n",
    "        source_filename = f\"{int(dataframe['geometry'][idx])}_{int(dataframe['path'][idx])}_{var_savefilename_init}.cif\"\n",
    "        source_filename_path = os.path.join(destination_directory, source_filename)\n",
    "\n",
    "        source_filename_filtered = f\"{int(dataframe['geometry'][idx])}_{int(dataframe['path'][idx])}_{var_savefilename_new}.cif\"\n",
    "        destination_path_combined_new = os.path.join(destination_directory, source_filename_filtered)\n",
    "\n",
    "        with open(source_filename_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for idx_line, line in enumerate(lines):\n",
    "            if search_string in line:\n",
    "                idx_Li_start = idx_line\n",
    "                break\n",
    "\n",
    "        idx_without_weirdos = [i for i in range(amount_Li) if i not in idx0_weirdos_Li]\n",
    "\n",
    "        new_text = []\n",
    "        for i in range(len(idx_without_weirdos)):\n",
    "            idx_line = idx_Li_start + i\n",
    "            if lines[idx_line].strip().startswith(\"Li\"):\n",
    "                new_label = f\"Li{idx_without_weirdos[i]}\"\n",
    "                modified_line = lines[idx_line].replace(lines[idx_line].split()[1], new_label)\n",
    "                new_text.append(modified_line)\n",
    "\n",
    "        lines[idx_Li_start : len(idx_without_weirdos) + idx_Li_start] = new_text\n",
    "\n",
    "        idx_P_S_Cl_line_new_start    = len(idx_without_weirdos) + idx_Li_start\n",
    "        reindex_P_S_Cl(lines, idx_Li_start, idx_without_weirdos, idx_P_S_Cl_line_new_start, amount_Li, amount_P, amount_S, amount_Cl)\n",
    "\n",
    "        dataframe.at[idx, col_idx_without_weirdos] = idx_without_weirdos\n",
    "\n",
    "        with open(destination_path_combined_new, \"w\") as f:\n",
    "            f.write(\"\\n\".join(line.strip() for line in lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reindex_P_S_Cl(lines, idx_Li_start, idx_without_weirdos, idx_P_S_Cl_line_new_start, amount_Li, amount_P, amount_S, amount_Cl):\n",
    "    old_text_P_S_Cl = lines[len(idx_without_weirdos) + idx_Li_start :]\n",
    "\n",
    "    idx_P_S_Cl_line_new_end      = idx_P_S_Cl_line_new_start + len(old_text_P_S_Cl)\n",
    "    lines[idx_P_S_Cl_line_new_start : idx_P_S_Cl_line_new_end] = old_text_P_S_Cl\n",
    "\n",
    "    # re-write the index of P_S_Cl accordingly\n",
    "    new_text_P_S_Cl = []\n",
    "    for i in range(amount_P):\n",
    "        idx_line_P = idx_P_S_Cl_line_new_start + i\n",
    "        idx_P_new = amount_Li + i\n",
    "        if lines[idx_line_P].strip().startswith(\"P\"):\n",
    "            new_label = f\"P{idx_P_new}\"\n",
    "            modified_line = lines[idx_line_P].replace(lines[idx_line_P].split()[1], new_label)\n",
    "            new_text_P_S_Cl.append(modified_line)\n",
    "    for i in range(amount_S):\n",
    "        idx_line_S = idx_P_S_Cl_line_new_start + amount_P + i\n",
    "        idx_S_new = amount_Li + amount_P + i\n",
    "        if lines[idx_line_S].strip().startswith(\"S\"):\n",
    "            new_label = f\"S{idx_S_new}\"\n",
    "            modified_line = lines[idx_line_S].replace(lines[idx_line_S].split()[1], new_label)\n",
    "            new_text_P_S_Cl.append(modified_line)\n",
    "    for i in range(amount_Cl):\n",
    "        idx_line_Cl = idx_P_S_Cl_line_new_start + amount_P + amount_S + i\n",
    "        idx_Cl_new = amount_Li + amount_P + amount_S + i\n",
    "        if lines[idx_line_Cl].strip().startswith(\"Cl\"):\n",
    "            new_label = f\"Cl{idx_Cl_new}\"\n",
    "            modified_line = lines[idx_line_Cl].replace(lines[idx_line_Cl].split()[1], new_label)\n",
    "            new_text_P_S_Cl.append(modified_line)\n",
    "\n",
    "    lines[idx_P_S_Cl_line_new_start : amount_P + amount_S + amount_Cl + idx_P_S_Cl_line_new_start] = new_text_P_S_Cl\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending weirdos in CIF (for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_cif_w_correct_Li_idx_weirdos_appended(dataframe, destination_directory, amount_Li, amount_P, amount_S, amount_Cl, var_savefilename_init, var_savefilename_new):\n",
    "    \n",
    "    search_string = \"Li  Li0\"\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        idx0_weirdos_Li = dataframe[\"idx0_weirdos_Li\"][idx]\n",
    "        source_filename = f\"{int(dataframe['geometry'][idx])}_{int(dataframe['path'][idx])}_{var_savefilename_init}.cif\"\n",
    "        source_filename_path = os.path.join(destination_directory, source_filename)\n",
    "\n",
    "        source_filename_filtered = f\"{int(dataframe['geometry'][idx])}_{int(dataframe['path'][idx])}_{var_savefilename_new}.cif\"\n",
    "        destination_path_combined_new = os.path.join(destination_directory, source_filename_filtered)\n",
    "\n",
    "        with open(source_filename_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        for idx_line, line in enumerate(lines):\n",
    "            if search_string in line:\n",
    "                idx_Li_start = idx_line\n",
    "                break\n",
    "\n",
    "        idx_without_weirdos = [i for i in range(amount_Li) if i not in idx0_weirdos_Li]\n",
    "\n",
    "        new_text = []\n",
    "        for i in range(len(idx_without_weirdos)):\n",
    "            idx_line = idx_Li_start + i\n",
    "            if lines[idx_line].strip().startswith(\"Li\"):\n",
    "                new_label = f\"Li{idx_without_weirdos[i]}\"\n",
    "                modified_line = lines[idx_line].replace(lines[idx_line].split()[1], new_label)\n",
    "                new_text.append(modified_line)\n",
    "\n",
    "        lines[idx_Li_start : len(idx_without_weirdos) + idx_Li_start] = new_text\n",
    "\n",
    "        # now appending weirdos below existing lines of Li\n",
    "        coor_weirdos = dataframe[\"coor_weirdos_48htypesmerged_Li\"][idx] # coor_weirdos = dataframe[\"coor_weirdos_Li\"][idx]\n",
    "\n",
    "        weirdos_text = []\n",
    "        for i in range(len(idx0_weirdos_Li)):\n",
    "            coor_weirdo_x = coor_weirdos[i][0]\n",
    "            coor_weirdo_y = coor_weirdos[i][1]\n",
    "            coor_weirdo_z = coor_weirdos[i][2]\n",
    "            idx_weirdo = idx0_weirdos_Li[i]\n",
    "            new_line_weirdo = f\"Li  Li{idx_weirdo}  1  {coor_weirdo_x:.8f}  {coor_weirdo_y:.8f}  {coor_weirdo_z:.8f}  1\"  # manually created\n",
    "            weirdos_text.append(new_line_weirdo)\n",
    "            # idx_line_weirdos = idx_Li_start + len(idx_without_weirdos)\n",
    "            \n",
    "        old_text_P_S_Cl = lines[len(idx_without_weirdos) + idx_Li_start :]\n",
    "\n",
    "        idx_weirdo_line_start   = len(idx_without_weirdos) + idx_Li_start\n",
    "        idx_weirdo_line_end     = idx_weirdo_line_start + len(idx0_weirdos_Li)\n",
    "        lines[idx_weirdo_line_start : idx_weirdo_line_end] = weirdos_text\n",
    "\n",
    "        idx_P_S_Cl_line_new_start    = idx_weirdo_line_end\n",
    "\n",
    "        # !!!: for the moment not using the function because P is gone\n",
    "        # reindex_P_S_Cl(lines, idx_Li_start, idx_without_weirdos, idx_P_S_Cl_line_new_start, amount_P, amount_S, amount_Cl)\n",
    "        \n",
    "        idx_P_S_Cl_line_new_end      = idx_P_S_Cl_line_new_start + len(old_text_P_S_Cl)\n",
    "        lines[idx_P_S_Cl_line_new_start : idx_P_S_Cl_line_new_end] = old_text_P_S_Cl\n",
    " \n",
    "        # re-write the index of P_S_Cl accordingly\n",
    "        new_text_P_S_Cl = []\n",
    "        for i in range(amount_P):\n",
    "            idx_line_P = idx_P_S_Cl_line_new_start + i\n",
    "            idx_P_new = amount_Li + i\n",
    "            if lines[idx_line_P].strip().startswith(\"P\"):\n",
    "                new_label = f\"P{idx_P_new}\"\n",
    "                modified_line = lines[idx_line_P].replace(lines[idx_line_P].split()[1], new_label)\n",
    "                new_text_P_S_Cl.append(modified_line)\n",
    "        for i in range(amount_S):\n",
    "            idx_line_S = idx_P_S_Cl_line_new_start + amount_P + i\n",
    "            idx_S_new = amount_Li + amount_P + i\n",
    "            if lines[idx_line_S].strip().startswith(\"S\"):\n",
    "                new_label = f\"S{idx_S_new}\"\n",
    "                modified_line = lines[idx_line_S].replace(lines[idx_line_S].split()[1], new_label)\n",
    "                new_text_P_S_Cl.append(modified_line)\n",
    "        for i in range(amount_Cl):\n",
    "            idx_line_Cl = idx_P_S_Cl_line_new_start + amount_P + amount_S + i\n",
    "            idx_Cl_new = amount_Li + amount_P + amount_S + i\n",
    "            if lines[idx_line_Cl].strip().startswith(\"Cl\"):\n",
    "                new_label = f\"Cl{idx_Cl_new}\"\n",
    "                modified_line = lines[idx_line_Cl].replace(lines[idx_line_Cl].split()[1], new_label)\n",
    "                new_text_P_S_Cl.append(modified_line)\n",
    "\n",
    "        lines[idx_P_S_Cl_line_new_start : amount_P + amount_S + amount_Cl + idx_P_S_Cl_line_new_start] = new_text_P_S_Cl\n",
    "\n",
    "        # dataframe.at[idx, col_subdir_cif_w_correct_Li_idx_weirdos_appended] = destination_path_combined_new\n",
    "\n",
    "        # Write the modified lines back to the file\n",
    "        with open(destination_path_combined_new, \"w\") as f:\n",
    "            f.write(\"\\n\".join(line.strip() for line in lines))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of all atoms in CONTCAR: type (48h type 1, 48h type 2, weirdo); amount of each type and weirdo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx_coor_limapped_weirdos_dict(dataframe, coor_structure_init_dict, el):\n",
    "    coor_origin120_el_init = coor_structure_init_dict[el]\n",
    "\n",
    "    col_idx_without_weirdos = \"idx_without_weirdos\"\n",
    "    col_coor_reduced120_corrected_Li_new = \"coor_reduced120_corrected_Li_new\"\n",
    "    col_coor_weirdos_48htypesmerged_Li = \"coor_weirdos_48htypesmerged_Li\"\n",
    "    col_idx0_weirdos_Li = \"idx0_weirdos_Li\"\n",
    "    col_nr_of_weirdos_Li = f\"#weirdos_Li\"\n",
    "    col_sum_sanitycheck_48htypesmerged_Li_new = \"sum_sanitycheck_48htypesmerged_Li_new\"\n",
    "\n",
    "    col_idx_coor_limapped_weirdos_dict = \"idx_coor_limapped_weirdos_dict\"\n",
    "    col_sum_label_and_weirdo_flag = \"#label_and_#weirdo_flag\"\n",
    "    col_amount_types_and_weirdo = \"amount_types_and_weirdo\"\n",
    "    col_ratio_48htype1_Li = \"ratio_48htype1_Li\"\n",
    "    col_ratio_48htype2_Li = \"ratio_48htype2_Li\"\n",
    "    col_ratio_24g_Li = \"ratio_24g_Li\"\n",
    "    col_ratio_weirdo_Li = \"ratio_weirdo_Li\"\n",
    "    col_sum_amount = \"sum_amount\"\n",
    "    col_idx_coor_limapped_weirdos_dict_init = \"idx_coor_limapped_weirdos_dict_init\"\n",
    "    col_ndim_coor_reduced120_corrected_Li_new = \"ndim_coor_reduced120_corrected_Li_new\"\n",
    "    col_ndim_coor_weirdos_48htypesmerged_Li = \"ndim_coor_weirdos_48htypesmerged_Li\"\n",
    "    col_len_coor_weirdos_48htypesmerged_Li = \"len_coor_weirdos_48htypesmerged_Li\"\n",
    "    col_len_coor_reduced120_corrected_Li_new = \"len_coor_reduced120_corrected_Li_new\"\n",
    "    col_len_idx0_weirdos_Li = \"len_idx0_weirdos_Li\"\n",
    "    col_len_idx_without_weirdos = \"len_idx_without_weirdos\"\n",
    "    col_ndim_flag_coor = \"ndim_flag_coor\"\n",
    "\n",
    "    dataframe[col_idx_coor_limapped_weirdos_dict] = [{} for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_sum_label_and_weirdo_flag] = \"False\"\n",
    "    dataframe[col_amount_types_and_weirdo] = [0 for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_sum_amount] = [0 for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_idx_coor_limapped_weirdos_dict_init] = [{} for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_ndim_coor_reduced120_corrected_Li_new] = [0 for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_ndim_coor_weirdos_48htypesmerged_Li] = [0 for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_len_coor_weirdos_48htypesmerged_Li] = [0 for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_len_coor_reduced120_corrected_Li_new] = [0 for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_len_idx0_weirdos_Li] = [0 for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_len_idx_without_weirdos] = [0 for _ in range(len(dataframe.index))]\n",
    "    dataframe[col_ndim_flag_coor] = \"False\"\n",
    "\n",
    "    coor_li48htype1_ref = coor_origin120_el_init[0:48]\n",
    "    coor_li48htype2_ref = coor_origin120_el_init[48:96]\n",
    "    coor_li24g_ref = coor_origin120_el_init[96:120]\n",
    "\n",
    "    for idx in range(dataframe[\"geometry\"].size):\n",
    "        coor_limapped_weirdos = []\n",
    "        idx0_limapped_weirdos = []\n",
    "        idx_coor_limapped_weirdos_dict_init = {}\n",
    "        idx_coor_limapped_weirdos_dict = {}\n",
    "\n",
    "        idx_without_weirdos = dataframe.at[idx, col_idx_without_weirdos]\n",
    "        coor_reduced120_corrected_Li_new = np.array(dataframe.at[idx, col_coor_reduced120_corrected_Li_new])\n",
    "        coor_weirdos_48htypesmerged_Li = np.array(dataframe.at[idx, col_coor_weirdos_48htypesmerged_Li])\n",
    "        idx0_weirdos_Li = dataframe.at[idx, col_idx0_weirdos_Li]\n",
    "        nr_of_weirdos_Li = dataframe.at[idx, col_nr_of_weirdos_Li]\n",
    "        sum_sanitycheck_48htypesmerged_Li_new = dataframe.at[idx, col_sum_sanitycheck_48htypesmerged_Li_new]\n",
    "\n",
    "        ndim_coor_reduced120_corrected_Li_new = coor_reduced120_corrected_Li_new.ndim\n",
    "        ndim_coor_weirdos_48htypesmerged_Li = coor_weirdos_48htypesmerged_Li.ndim\n",
    "        len_coor_weirdos_48htypesmerged_Li = len(coor_weirdos_48htypesmerged_Li)\n",
    "        len_coor_reduced120_corrected_Li_new = len(coor_reduced120_corrected_Li_new)\n",
    "        len_idx0_weirdos_Li = len(idx0_weirdos_Li)\n",
    "        len_idx_without_weirdos = len(idx_without_weirdos)\n",
    "    \n",
    "        if ndim_coor_reduced120_corrected_Li_new == ndim_coor_weirdos_48htypesmerged_Li & ndim_coor_weirdos_48htypesmerged_Li == 2:\n",
    "            coor_limapped_weirdos = np.concatenate((coor_reduced120_corrected_Li_new, coor_weirdos_48htypesmerged_Li), axis=0)\n",
    "            dataframe.at[idx, col_ndim_flag_coor] = \"True\"\n",
    "        elif ndim_coor_weirdos_48htypesmerged_Li == 1:\n",
    "            coor_limapped_weirdos = np.array(coor_reduced120_corrected_Li_new.copy())\n",
    "        elif ndim_coor_reduced120_corrected_Li_new == 1:\n",
    "            coor_limapped_weirdos = np.array(coor_weirdos_48htypesmerged_Li.copy())\n",
    "        else:\n",
    "            print(f\"coor_weirdos_48htypesmerged_Li or coor_reduced120_corrected_Li_new has no correct dimension at idx: {idx}\")\n",
    "\n",
    "        if len(idx0_weirdos_Li) > 0:\n",
    "            idx0_limapped_weirdos = np.concatenate((idx_without_weirdos, idx0_weirdos_Li), axis=0)\n",
    "        elif len(idx0_weirdos_Li) == 0:\n",
    "            idx0_limapped_weirdos = np.array(idx_without_weirdos.copy())\n",
    "        elif len(idx_without_weirdos) == 0:\n",
    "            idx0_limapped_weirdos = np.array(idx0_weirdos_Li.copy())\n",
    "        else:\n",
    "            print(f\"idx0_weirdos_Li or idx_without_weirdos has no correct len at idx: {idx}\")\n",
    "\n",
    "        idx_coor_limapped_weirdos_dict_init = dict(zip(idx0_limapped_weirdos, coor_limapped_weirdos))\n",
    "\n",
    "        coor_48htype1_Li = []; coor_48htype2_Li = []; coor_24g_Li = []; coor_weirdo_Li = []\n",
    "        for key, value in idx_coor_limapped_weirdos_dict_init.items():\n",
    "            idx_coor_limapped_weirdos_dict_val = {}\n",
    "\n",
    "            idx_coor_limapped_weirdos_dict_val['coor'] = tuple(value)\n",
    "\n",
    "            for idx_li48htype1_temp, coor_li48htype1_ref_temp in enumerate(coor_li48htype1_ref):\n",
    "                if (value == coor_li48htype1_ref_temp).all():\n",
    "                    idx_coor_limapped_weirdos_dict_val[\"type\"] = \"48htype1\"\n",
    "                    coor_48htype1_Li.append(np.array(list(value)))\n",
    "                    if int(key) in idx_coor_limapped_weirdos_dict:\n",
    "                        idx_coor_limapped_weirdos_dict[int(key)].append(idx_coor_limapped_weirdos_dict_val)\n",
    "                    else:\n",
    "                        idx_coor_limapped_weirdos_dict[int(key)] = idx_coor_limapped_weirdos_dict_val\n",
    "            for idx_li48htype2_temp, coor_li48htype2_ref_temp in enumerate(coor_li48htype2_ref):\n",
    "                if (value == coor_li48htype2_ref_temp).all():\n",
    "                    idx_coor_limapped_weirdos_dict_val[\"type\"] = \"48htype2\"\n",
    "                    coor_48htype2_Li.append(np.array(list(value)))\n",
    "                    if int(key) in idx_coor_limapped_weirdos_dict:\n",
    "                        idx_coor_limapped_weirdos_dict[int(key)].append(idx_coor_limapped_weirdos_dict_val)\n",
    "                    else:\n",
    "                        idx_coor_limapped_weirdos_dict[int(key)] = idx_coor_limapped_weirdos_dict_val\n",
    "            for idx_24g_temp, coor_li24g_ref_temp in enumerate(coor_li24g_ref):\n",
    "                if (value == coor_li24g_ref_temp).all():\n",
    "                    idx_coor_limapped_weirdos_dict_val[\"type\"] = \"24g\"\n",
    "                    coor_24g_Li.append(np.array(list(value)))\n",
    "                    if int(key) in idx_coor_limapped_weirdos_dict:\n",
    "                        idx_coor_limapped_weirdos_dict[int(key)].append(idx_coor_limapped_weirdos_dict_val)\n",
    "                    else:\n",
    "                        idx_coor_limapped_weirdos_dict[int(key)] = idx_coor_limapped_weirdos_dict_val\n",
    "            for idx_weirdos_temp, coor_weirdos_ref_temp in enumerate(coor_weirdos_48htypesmerged_Li):\n",
    "                if (value == coor_weirdos_ref_temp).all():\n",
    "                    idx_coor_limapped_weirdos_dict_val[\"type\"] = \"weirdos\"\n",
    "                    coor_weirdo_Li.append(np.array(list(value)))\n",
    "                    if int(key) in idx_coor_limapped_weirdos_dict:\n",
    "                        idx_coor_limapped_weirdos_dict[int(key)].append(idx_coor_limapped_weirdos_dict_val)\n",
    "                    else:\n",
    "                        idx_coor_limapped_weirdos_dict[int(key)] = idx_coor_limapped_weirdos_dict_val\n",
    "\n",
    "\n",
    "        # amount of each type\n",
    "        amount_48htype1_Li = len(coor_48htype1_Li)\n",
    "        amount_48htype2_Li = len(coor_48htype2_Li)\n",
    "        amount_24g_Li = len(coor_24g_Li)\n",
    "        amount_weirdo = len(coor_weirdo_Li)\n",
    "        sum_amount = amount_48htype1_Li + amount_48htype2_Li + amount_24g_Li + amount_weirdo\n",
    "\n",
    "        # sanity check for the amount\n",
    "        # if amount_weirdo == nr_of_weirdos_Li & sum_amount == sum_sanitycheck_48htypesmerged_Li_new:\n",
    "        # if int(amount_weirdo) == int(nr_of_weirdos_Li) & int(sum_amount) == int(sum_sanitycheck_48htypesmerged_Li_new):\n",
    "        if int(amount_weirdo) == int(nr_of_weirdos_Li):\n",
    "            if int(sum_amount) == int(sum_sanitycheck_48htypesmerged_Li_new):\n",
    "                dataframe.at[idx, col_sum_label_and_weirdo_flag] = \"True\"\n",
    "\n",
    "        amount_types_and_weirdo = f\"48htype1: {amount_48htype1_Li}, 48htype2: {amount_48htype2_Li}, 24g: {amount_24g_Li}, weirdo: {amount_weirdo}\"\n",
    "\n",
    "        # ratio_48htype1_Li = amount_48htype1_Li / sum_amount\n",
    "        # ratio_48htype2_Li = amount_48htype2_Li / sum_amount\n",
    "        # ratio_24g_Li = amount_24g_Li / sum_amount\n",
    "        # ratio_weirdo_Li = amount_weirdo / sum_amount\n",
    "\n",
    "        dataframe.at[idx, col_idx_coor_limapped_weirdos_dict] = idx_coor_limapped_weirdos_dict\n",
    "        dataframe.at[idx, col_amount_types_and_weirdo] = amount_types_and_weirdo\n",
    "        # dataframe.at[idx, col_ratio_48htype1_Li] = ratio_48htype1_Li\n",
    "        # dataframe.at[idx, col_ratio_48htype2_Li] = ratio_48htype2_Li\n",
    "        # dataframe.at[idx, col_ratio_24g_Li] = ratio_24g_Li\n",
    "        # dataframe.at[idx, col_ratio_weirdo_Li] = ratio_weirdo_Li\n",
    "        dataframe.at[idx, col_sum_amount] = sum_amount\n",
    "        dataframe.at[idx, col_idx_coor_limapped_weirdos_dict_init] = idx_coor_limapped_weirdos_dict_init\n",
    "        dataframe.at[idx, col_ndim_coor_reduced120_corrected_Li_new] = ndim_coor_reduced120_corrected_Li_new\n",
    "        dataframe.at[idx, col_ndim_coor_weirdos_48htypesmerged_Li] = ndim_coor_weirdos_48htypesmerged_Li\n",
    "        dataframe.at[idx, col_len_coor_weirdos_48htypesmerged_Li] = len_coor_weirdos_48htypesmerged_Li\n",
    "        dataframe.at[idx, col_len_coor_reduced120_corrected_Li_new] = len_coor_reduced120_corrected_Li_new\n",
    "        dataframe.at[idx, col_len_idx0_weirdos_Li] = len_idx0_weirdos_Li\n",
    "        dataframe.at[idx, col_len_idx_without_weirdos] = len_idx_without_weirdos"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azka311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
